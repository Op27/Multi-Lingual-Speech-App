from flask import Flask, request, jsonify, Response
import requests
from google.cloud import speech, texttospeech
from pydub import AudioSegment
import io
import logging
from datetime import datetime  # Add this import at the beginning of your file
from google.cloud import texttospeech

logging.basicConfig(level=logging.DEBUG)

processed_sessions = set()
app = Flask(__name__)

# Initialize Google Cloud Speech and Text-to-Speech clients
speech_client = speech.SpeechClient()
tts_client = texttospeech.TextToSpeechClient()

@app.route('/upload_audio', methods=['POST'])
def upload_audio(audio_file=None):
    if not audio_file:
        if 'audio' not in request.files:
            return jsonify({"message": "No audio file in request"}), 400
        audio_file = request.files['audio']

    audio_data = audio_file.read()
    audio_segment = AudioSegment.from_file(io.BytesIO(audio_data)).set_channels(1)

    if audio_segment.sample_width != 2:
        audio_segment = audio_segment.set_sample_width(2)
    if audio_segment.frame_rate != 16000:
        audio_segment = audio_segment.set_frame_rate(16000)

    audio_bytes = audio_segment.raw_data

    audio = speech.RecognitionAudio(content=audio_bytes)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="en-US",
        audio_channel_count=1,
        enable_automatic_punctuation=True
    )

    try:
        response = speech_client.recognize(config=config, audio=audio)
        transcript = response.results[0].alternatives[0].transcript
        return jsonify({"transcript": transcript})
    except Exception as e:
        return jsonify({"message": "Error processing audio", "error": str(e)}), 500

language_code_map = {
    'Spanish': 'es',  # Spanish language code
    'French': 'fr',   # Corrected French language code
    # Add other languages and their codes as needed
}


@app.route('/translate_text', methods=['POST'])
def translate_text():
    data = request.get_json(force=True)

    # Logging the received data for debugging
    logging.debug(f"Received data for translation: {data}")

    text_to_translate = data.get('text')
    target_language = data.get('language').capitalize()

    # Check if the target language is supported
    if target_language not in language_code_map:
        return jsonify({"message": f"Unsupported target language: {target_language}"}), 400

    target_language_code = language_code_map[target_language]

    # Logging the target language code
    logging.debug(f"Target language code: {target_language_code}")

    deepL_api_key = '3bf6993a-c2bf-f760-715e-dd6f4024b659:fx'  # Your DeepL API key
    url = "https://api-free.deepl.com/v2/translate"

    params = {
        'auth_key': deepL_api_key,
        'text': text_to_translate,
        'target_lang': target_language_code
    }

    response = requests.post(url, data=params)

    # Logging the response from the DeepL API
    logging.debug(f"DeepL API Response: {response.status_code}, {response.text}")

    if response.status_code == 200:
        translated_text = response.json()['translations'][0]['text']
        return jsonify({"translated_text": translated_text})
    else:
        error_msg = f"DeepL API error: {response.status_code} - {response.text}"
        logging.error(error_msg)
        return jsonify({"message": "Translation failed", "error": error_msg}), response.status_code

tts_language_voice_map = {
        'es': 'es-ES-Standard-B',  # Spanish male voice
        'fr': 'fr-FR-Standard-B',  # French male voice
        # Add other mappings as needed
    }

@app.route('/synthesize_speech', methods=['POST'])
def synthesize_speech():
    data = request.get_json()
    text = data.get('text')
    language_code = data.get('language', 'en-US')  # Default to US English if not provided

# Retrieve the voice name from the mapping
    voice_name = tts_language_voice_map.get(language_code, 'en-US-Standard-B')  # Default to a US English male voice

    synthesis_input = texttospeech.SynthesisInput(text=text)
    voice = texttospeech.VoiceSelectionParams(
        language_code=language_code,  # Use the language code here
        name=voice_name,              # Use the mapped voice name
        ssml_gender=texttospeech.SsmlVoiceGender.MALE
    )
    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)

    try:
        response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)

        if len(response.audio_content) == 0:
            logging.error("No audio content generated by the Text-to-Speech API.")
            return jsonify({"message": "Error synthesizing speech: No audio content"}), 500
        
        return Response(response.audio_content, mimetype='audio/mp3')

    except Exception as e:
        logging.error(f"Error in text-to-speech synthesis: {e}")
        return jsonify({"message": "Error in text-to-speech synthesis", "error": str(e)}), 500


@app.route('/process_audio', methods=['POST'])
def process_audio():
    session_id = request.form.get('recordingSessionId')
    if session_id in processed_sessions:
        return jsonify({"message": "This audio has already been processed."}), 400
    
    processed_sessions.add(session_id)
    logging.debug("process_audio endpoint called") 
    if 'audio' not in request.files or 'language' not in request.form:
        logging.error("Audio file or language not provided in the request.")
        return jsonify({"message": "Audio file or language not provided"}), 400

    audio_file = request.files['audio']
    selected_language = request.form['language']

    # Debug log for received audio file and selected language
    logging.debug(f"Received audio file: {audio_file.filename}")
    logging.debug(f"Selected language: {selected_language}")
    

    try:
        # Save the received audio file for debugging
        # temp_audio_filename = f"temp_audio_{datetime.now().strftime('%Y%m%d%H%M%S')}.wav"
        # logging.debug(f"Attempting to save audio file: {temp_audio_filename}")
        # try:
        #     audio_file.save(temp_audio_filename)
        #     logging.debug(f"Audio file saved: {temp_audio_filename}")
        # except Exception as e:
        #     logging.error(f"Error saving audio file: {e}")
        #     return jsonify({"message": f"Error saving audio file: {str(e)}"}), 500

        audio_file.seek(0)  # Reset file read pointer
        audio_data = audio_file.read()
        logging.debug(f"Size of audio data: {len(audio_data)} bytes")

        audio_segment = AudioSegment.from_file(io.BytesIO(audio_data)).set_channels(1)
        logging.debug(f"Audio Segment: Channels - {audio_segment.channels}, Frame Rate - {audio_segment.frame_rate}, Sample Width - {audio_segment.sample_width}")

        if audio_segment.sample_width != 2:
            audio_segment = audio_segment.set_sample_width(2)
        if audio_segment.frame_rate != 16000:
            audio_segment = audio_segment.set_frame_rate(16000)


        audio_bytes = audio_segment.raw_data
        audio = speech.RecognitionAudio(content=audio_bytes)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="en-US",
            audio_channel_count=1,
            enable_automatic_punctuation=True
        )

        response = speech_client.recognize(config=config, audio=audio)

        if not response.results:
            logging.error("No transcription results.")
            return jsonify({"message": "Error in transcription: No results"}), 500

        transcript = response.results[0].alternatives[0].transcript
        logging.debug(f"Transcript (English): {transcript}")
        
        transcript = response.results[0].alternatives[0].transcript

        logging.debug(f"Transcript (English): {transcript}")

        # Translate the transcript
        translation_response = requests.post('http://localhost:5000/translate_text', json={'text': transcript, 'language': selected_language})
        if translation_response.status_code != 200:
            return jsonify({"message": "Error translating text"}), translation_response.status_code
        translated_text = translation_response.json()['translated_text']

        logging.debug(f"Translated text (Target Language - {selected_language}): {translated_text}")

        # Synthesize speech from the translated text
        speech_response = requests.post('http://localhost:5000/synthesize_speech', json={'text': translated_text, 'language': selected_language})
        if speech_response.status_code != 200:
            return jsonify({"message": "Error synthesizing speech"}), speech_response.status_code
        audio_content = speech_response.content

        logging.debug(f"Type of audio content: {type(audio_content)}")
        logging.debug(f"Length of audio content: {len(audio_content)}")
        logging.debug(f"Transcription and translation completed successfully.")

        return jsonify({"transcript": transcript, "translated_text": translated_text})

    except Exception as e:
        logging.error(f"Error in processing audio: {e}")
        return jsonify({"message": "Error in processing audio", "error": str(e)}), 500


@app.route('/')
def index():
    return app.send_static_file('index.html')


if __name__ == '__main__':
    app.run(debug=True)